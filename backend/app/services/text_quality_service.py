# coding: utf-8
import pandas as pd
import os
import time
import asyncio
import re
from app.services.llm_client import LLMClient
from app.services.database_service import DatabaseService
from app.models.quality_result import QualityResult, QualityReport
from app import db

class TextQualityService:
    """æ–‡æœ¬æ•°æ®è´¨æ£€æœåŠ¡"""
    
    def __init__(self, batch_size=100):
        self.llm_client = LLMClient()
        self.batch_size = min(batch_size, 1000)  # æ‰¹å¤„ç†å¤§å°ï¼Œé»˜è®¤100æ¡ï¼Œæœ€å¤§1000æ¡
        self._max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
        self._retry_delay = 1.0  # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
        
        # äº•åæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        self.well_name_pattern = re.compile(
            r'^(?P<oil_field>[A-Z]+\d+(?:-\d+)*)-(?P<wellhead_area>[A-Z])(?P<well_number>\d+)(?P<well_marker>(?:H\d*|M\d*(?:[a-z]\d*)?|P\d+|S\d+)?)$'
        )
        
        # åŠ è½½åŒºå—ä»£å·ç™½åå•ï¼ˆæ¥è‡ª backend/block_info.csv çš„â€œä»£å·â€åˆ—ï¼‰
        self.block_code_whitelist = self._load_block_codes()
        print(f"åŠ è½½åŒºå—ä»£å·ç™½åå•å®Œæˆï¼Œæ•°é‡: {len(self.block_code_whitelist)}")
    
    def _load_block_codes(self):
        """ä» CSV åŠ è½½åŒºå—ä»£å·ç™½åå•ï¼ˆåˆ—åï¼šä»£å·ï¼‰"""
        try:
            # è®¡ç®— CSV è·¯å¾„ï¼šä»å½“å‰æ–‡ä»¶åˆ° backend ç›®å½•
            backend_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
            csv_path = os.path.join(backend_dir, 'block_info.csv')
            if not os.path.exists(csv_path):
                print(f"æœªæ‰¾åˆ°åŒºå—ä»£å·æ–‡ä»¶: {csv_path}")
                return set()
            df = pd.read_csv(csv_path, dtype=str)
            if 'ä»£å·' not in df.columns:
                print("CSVä¸­æœªæ‰¾åˆ°â€˜ä»£å·â€™åˆ—")
                return set()
            codes = set(str(x).strip().upper() for x in df['ä»£å·'].dropna().tolist() if str(x).strip())
            return codes
        except Exception as e:
            print(f"åŠ è½½åŒºå—ä»£å·ç™½åå•å¤±è´¥: {e}")
            return set()
    
    def _is_well_name_field(self, kb_field_name):
        """åˆ¤æ–­å­—æ®µæ˜¯å¦ä¸ºäº•åå­—æ®µ"""
        # æ£€æŸ¥çŸ¥è¯†åº“å­—æ®µåæ˜¯å¦ä¸ºäº•å
        return kb_field_name == 'äº•å'
    
    def _validate_well_name(self, well_name):
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼éªŒè¯äº•åæ ¼å¼ï¼›è‹¥å‰ç¼€å­—æ¯åœ¨åŒºå—ä»£å·ç™½åå•å†…ï¼Œç›´æ¥æ”¾è¡Œ"""
        if not well_name or pd.isna(well_name):
            return False, "äº•åä¸ºç©º"
        
        well_name_str = str(well_name).strip().upper()
        if not well_name_str:
            return False, "äº•åä¸ºç©ºå­—ç¬¦ä¸²"
        
        # 1) ç™½åå•å‰ç¼€å¿«é€Ÿæ”¾è¡Œï¼šæå–æœ€å‰é¢çš„è¿ç»­å¤§å†™å­—æ¯ä½œä¸ºå‰ç¼€
        prefix_match = re.match(r'^([A-Z]+)', well_name_str)
        if prefix_match:
            prefix = prefix_match.group(1)
            if prefix in self.block_code_whitelist:
                return True, f"ç™½åå•ä»£å·: {prefix}ï¼Œç›´æ¥æ”¾è¡Œ"
        
        # 2) æ­£åˆ™æ ¼å¼æ ¡éªŒ
        match = self.well_name_pattern.match(well_name_str)
        if match:
            oil_field = match.group('oil_field')
            wellhead_area = match.group('wellhead_area')
            well_number = match.group('well_number')
            well_marker = match.group('well_marker') or ''
            
            explanation = f"æ²¹ç”°:{oil_field}, äº•åŒº:{wellhead_area}, äº•å·:{well_number}"
            if well_marker:
                explanation += f", æ ‡è®°:{well_marker}"
            
            return True, explanation
        else:
            return False, f"äº•åæ ¼å¼ä¸ç¬¦åˆè§„èŒƒ: {well_name_str}"
    
    def _preprocess_well_name_fields(self, all_check_items):
        """é¢„å¤„ç†äº•åå­—æ®µï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼éªŒè¯"""
        well_name_results = []
        remaining_items = []
        
        for item in all_check_items:
            field_name = item['field_name']
            kb_field_name = item['kb_field_name']
            field_value = item['field_value']
            record_idx = item['record_idx']
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºäº•åå­—æ®µï¼ˆé€šè¿‡çŸ¥è¯†åº“å­—æ®µååˆ¤æ–­ï¼‰
            if self._is_well_name_field(kb_field_name):
                print(f"æ£€æµ‹åˆ°äº•åå­—æ®µ: {field_name} -> {kb_field_name}")
                
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼éªŒè¯
                is_valid, explanation = self._validate_well_name(field_value)
                
                well_name_results.append({
                    'è®°å½•ç¼–å·': record_idx,
                    'åŸå­—æ®µ': field_name,
                    'æ˜ å°„å­—æ®µ': kb_field_name,
                    'å˜é‡': kb_field_name,
                    'å€¼': str(field_value),
                    'ç±»åˆ«': item['category'],
                    'ç»“æœ': 'åˆæ ¼' if is_valid else 'ä¸åˆæ ¼',
                    'è¯´æ˜': explanation,
                    'è§„èŒƒ': item['quality_spec'],
                    'éªŒè¯æ–¹å¼': 'æ­£åˆ™è¡¨è¾¾å¼'
                })
                
                print(f"äº•åæ­£åˆ™éªŒè¯å®Œæˆ: è®°å½•{record_idx} {field_name} -> {'åˆæ ¼' if is_valid else 'ä¸åˆæ ¼'}")
            else:
                remaining_items.append(item)
        
        print(f"äº•åé¢„å¤„ç†å®Œæˆ: æ­£åˆ™éªŒè¯ {len(well_name_results)} ä¸ªï¼Œå¾…å¤§æ¨¡å‹æ£€æŸ¥ {len(remaining_items)} ä¸ª")
        return well_name_results, remaining_items
    
    def set_batch_size(self, batch_size):
        """è®¾ç½®æ‰¹å¤„ç†å¤§å°"""
        if batch_size > 0 and batch_size <= 1000:
            self.batch_size = batch_size
            print(f"æ‰¹å¤„ç†å¤§å°å·²è®¾ç½®ä¸º: {self.batch_size}")
        elif batch_size > 1000:
            self.batch_size = 1000
            print(f"æ‰¹å¤„ç†å¤§å°è¶…è¿‡æœ€å¤§é™åˆ¶ï¼Œå·²è®¾ç½®ä¸º: {self.batch_size}")
        else:
            print("æ‰¹å¤„ç†å¤§å°å¿…é¡»å¤§äº0ä¸”ä¸è¶…è¿‡1000")
    
    def get_batch_size(self):
        """è·å–å½“å‰æ‰¹å¤„ç†å¤§å°"""
        return self.batch_size
    
    def load_embedded_knowledge_base(self):
        """åŠ è½½å†…åµŒçš„çŸ¥è¯†åº“æ–‡ä»¶ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰"""
        try:

            base_dir = os.path.dirname(os.path.dirname(__file__))  # ä» services åˆ° app
            base_dir = os.path.dirname(base_dir)  # ä» app åˆ° backend
            kb_path = os.path.join(base_dir, 'æ–‡æœ¬å‹çŸ¥è¯†åº“.xlsx')
            
            print(f"åŠ è½½çŸ¥è¯†åº“æ–‡ä»¶: {kb_path}")
            
            if not os.path.exists(kb_path):
                raise FileNotFoundError(f"çŸ¥è¯†åº“æ–‡ä»¶æœªæ‰¾åˆ°: {kb_path}")
            
            # è¯»å–Excelæ–‡ä»¶
            df = pd.read_excel(kb_path)
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            knowledge_base = []
            for _, row in df.iterrows():
                knowledge_base.append({
                    'Variable': str(row.get('Variable', '')),
                    'Category': str(row.get('Category', '')),
                    'è´¨é‡è§„èŒƒæè¿°': str(row.get('è´¨é‡è§„èŒƒæè¿°', ''))
                })
            
            print(f"æˆåŠŸåŠ è½½çŸ¥è¯†åº“ï¼ŒåŒ…å« {len(knowledge_base)} æ¡è®°å½•")
            return knowledge_base
        
        except Exception as e:
            print(f"åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {str(e)}")
            raise e
    
    def _create_batch_prompt(self, batch_data, field_mapping_info, kb_map):
        prompt_parts = []
        
        # ç³»ç»Ÿè§’è‰²å®šä¹‰ - å¼ºè°ƒé€»è¾‘è§„åˆ™æ‰§è¡Œ
        prompt_parts.append("ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®è´¨é‡æ£€æŸ¥ä¸“å®¶ï¼Œå…·æœ‰ä¸°å¯Œçš„çŸ³æ²¹å‹˜æ¢å¼€å‘æ•°æ®è´¨æ£€ç»éªŒã€‚")
        prompt_parts.append("ä½ çš„ä»»åŠ¡æ˜¯ï¼šæ ¹æ®æä¾›çš„ç»“æ„åŒ–è´¨æ£€è§„åˆ™ï¼ˆIF-THENé€»è¾‘ï¼‰ï¼Œä¸¥æ ¼åˆ¤æ–­æ¯ä¸ªæ•°æ®å­—æ®µæ˜¯å¦åˆæ ¼ã€‚")
        prompt_parts.append("ã€æ ¸å¿ƒåŸåˆ™ã€‘è§„åˆ™å°±æ˜¯æ³•å¾‹ï¼Œå¿…é¡»100%ä¸¥æ ¼æ‰§è¡Œï¼Œä¸å¾—æœ‰ä»»ä½•ä¸»è§‚åˆ¤æ–­æˆ–åç¦»ã€‚")
        prompt_parts.append("")
        
        # è§„åˆ™è¯­è¨€è¯´æ˜ - æ•™ä¼šå¤§æ¨¡å‹ç†è§£IF-THENé€»è¾‘
        prompt_parts.append("ã€è§„åˆ™è¯­è¨€ç†è§£æŒ‡å—ã€‘")
        prompt_parts.append("è´¨æ£€è§„åˆ™é‡‡ç”¨IF-THENç»“æ„åŒ–é€»è¾‘ï¼Œä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§é€»è¾‘æ‰§è¡Œï¼š")
        prompt_parts.append("")
        prompt_parts.append("1. é€»è¾‘å‡½æ•°è§£é‡Šï¼š")
        prompt_parts.append("   - `is_null_or_blank(å­—æ®µ)` = å­—æ®µä¸ºç©ºã€nullã€Noneã€NaNæˆ–ä»…åŒ…å«ç©ºæ ¼")
        prompt_parts.append("   - `å­—æ®µ NOT IN {å€¼1ã€å€¼2}` = å­—æ®µå€¼ä¸åœ¨æšä¸¾åˆ—è¡¨ä¸­")
        prompt_parts.append("   - `NOT (å¤§äºç­‰äºXå¹¶ä¸”å°äºç­‰äºY)` = æ•°å€¼ä¸åœ¨[X,Y]èŒƒå›´å†…")
        prompt_parts.append("   - `filename_match_pattern(å­—æ®µ, 'æ¨¡å¼')` = æ–‡ä»¶åä¸ç¬¦åˆæŒ‡å®šå‘½åè§„èŒƒ")
        prompt_parts.append("")
        prompt_parts.append("2. é€»è¾‘æ‰§è¡Œè§„åˆ™ï¼š")
        prompt_parts.append("   - IFæ¡ä»¶ä¸ºçœŸ â†’ THENæ ‡è®°é”™è¯¯ â†’ åˆ¤å®šä¸ºã€ä¸åˆæ ¼ã€‘")
        prompt_parts.append("   - IFæ¡ä»¶ä¸ºå‡ â†’ ä¸è§¦å‘é”™è¯¯ â†’ è¯¥æ¡è§„åˆ™é€šè¿‡")
        prompt_parts.append("   - å¤šæ¡è§„åˆ™ï¼šåªè¦ä»»æ„ä¸€æ¡IFæ¡ä»¶ä¸ºçœŸï¼Œå°±åˆ¤å®šã€ä¸åˆæ ¼ã€‘")
        prompt_parts.append("   - æ‰€æœ‰è§„åˆ™éƒ½ä¸è§¦å‘é”™è¯¯ï¼Œæ‰åˆ¤å®šã€åˆæ ¼ã€‘")
        prompt_parts.append("")
        prompt_parts.append("3. ç‰¹åˆ«æ³¨æ„äº‹é¡¹ï¼š")
        prompt_parts.append("   - æ•°å€¼èŒƒå›´ï¼šå¿…é¡»ç²¾ç¡®æ¯”è¾ƒï¼ŒåŒ…æ‹¬å•ä½ï¼ˆMPaã€kPaã€â„ƒç­‰ï¼‰")
        prompt_parts.append("   - æšä¸¾å€¼ï¼šå¿…é¡»å®Œå…¨åŒ¹é…ï¼ŒåŒºåˆ†å¤§å°å†™å’Œæ ‡ç‚¹ç¬¦å·")
        prompt_parts.append("   - ç©ºå€¼åˆ¤æ–­ï¼šnullã€Noneã€NaNã€ç©ºå­—ç¬¦ä¸²ã€çº¯ç©ºæ ¼éƒ½è§†ä¸ºç©ºå€¼")
        prompt_parts.append("")
        
        # è¾“å‡ºæ ¼å¼è¦æ±‚
        prompt_parts.append("ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘ç»å¯¹ä¸å¾—æ›´æ”¹")
        prompt_parts.append("æ ¼å¼ï¼šè®°å½•{ç¼–å·}|{å­—æ®µå}|{ç»“æœ}|{è¯¦ç»†è¯´æ˜}")
        prompt_parts.append("")
        prompt_parts.append("è¯´æ˜ï¼š")
        prompt_parts.append("- è®°å½•ç¼–å·ï¼šçº¯æ•°å­—ï¼ˆ1, 2, 3...ï¼‰")
        prompt_parts.append("- å­—æ®µåï¼šä½¿ç”¨æä¾›çš„ä¸­æ–‡å­—æ®µå")
        prompt_parts.append("- ç»“æœï¼šåªèƒ½æ˜¯'åˆæ ¼'æˆ–'ä¸åˆæ ¼'ï¼ˆæ— å…¶ä»–è¡¨è¿°ï¼‰")
        prompt_parts.append("- è¯¦ç»†è¯´æ˜ï¼šè§¦å‘çš„å…·ä½“è§„åˆ™æˆ–é€šè¿‡åŸå› ï¼ˆ10-30å­—ï¼‰")
        prompt_parts.append("")
        
        # æ‰§è¡Œæ­¥éª¤ - æ¸…æ™°çš„åˆ¤æ–­æµç¨‹
        prompt_parts.append("ã€è´¨æ£€æ‰§è¡Œæ­¥éª¤ã€‘")
        prompt_parts.append("å¯¹æ¯æ¡æ•°æ®ï¼ŒæŒ‰ä»¥ä¸‹æ­¥éª¤ä¸¥æ ¼æ‰§è¡Œï¼š")
        prompt_parts.append("")
        prompt_parts.append("æ­¥éª¤1ï¼šè¯»å–è¯¥å­—æ®µçš„æ‰€æœ‰IF-THENè§„åˆ™")
        prompt_parts.append("æ­¥éª¤2ï¼šé€æ¡æ£€æŸ¥æ¯ä¸ªIFæ¡ä»¶æ˜¯å¦ä¸ºçœŸ")
        prompt_parts.append("   - å¦‚æœIFæ¡ä»¶ä¸ºçœŸ â†’ è§¦å‘THENä¸­çš„é”™è¯¯ â†’ è®°å½•é”™è¯¯ä¿¡æ¯")
        prompt_parts.append("æ­¥éª¤3ï¼šæ±‡æ€»åˆ¤æ–­ç»“æœ")
        prompt_parts.append("   - ä»»æ„è§„åˆ™è§¦å‘é”™è¯¯ â†’ åˆ¤å®šã€ä¸åˆæ ¼ã€‘ï¼Œè¯´æ˜å…·ä½“è§¦å‘äº†å“ªæ¡è§„åˆ™")
        prompt_parts.append("   - æ‰€æœ‰è§„åˆ™éƒ½æœªè§¦å‘ â†’ åˆ¤å®šã€åˆæ ¼ã€‘ï¼Œè¯´æ˜ç¬¦åˆæ‰€æœ‰è§„åˆ™è¦æ±‚")
        prompt_parts.append("")
        
        # ç¤ºä¾‹ - åŸºäºIF-THENè§„åˆ™çš„å®é™…ç¤ºä¾‹
        prompt_parts.append("ã€è¾“å‡ºç¤ºä¾‹ã€‘å®Œå…¨æŒ‰ç…§æ­¤æ ¼å¼")
        prompt_parts.append("")
        prompt_parts.append("ç¤ºä¾‹1ï¼šç©ºå€¼æ£€æŸ¥")
        prompt_parts.append("è§„åˆ™ï¼šIF is_null_or_blank(äº•å) THEN æ ‡è®°é”™è¯¯('å­—æ®µã€äº•åã€‘ä¸èƒ½ä¸ºç©º')")
        prompt_parts.append("æ•°æ®ï¼šäº•å=''")
        prompt_parts.append("è¾“å‡ºï¼šè®°å½•1|äº•å|ä¸åˆæ ¼|å­—æ®µä¸èƒ½ä¸ºç©º")
        prompt_parts.append("")
        prompt_parts.append("ç¤ºä¾‹2ï¼šæšä¸¾æ£€æŸ¥")
        prompt_parts.append("è§„åˆ™ï¼šIF æ˜¯å¦ä¸ºé˜²çˆ†è®¾å¤‡ NOT IN {æ˜¯ã€å¦} THEN æ ‡è®°é”™è¯¯('å–å€¼å¿…é¡»ä¸ºï¼šæ˜¯ã€å¦')")
        prompt_parts.append("æ•°æ®ï¼šæ˜¯å¦ä¸ºé˜²çˆ†è®¾å¤‡='æœªçŸ¥'")
        prompt_parts.append("è¾“å‡ºï¼šè®°å½•1|æ˜¯å¦ä¸ºé˜²çˆ†è®¾å¤‡|ä¸åˆæ ¼|å–å€¼ä¸åœ¨æšä¸¾{æ˜¯ã€å¦}ä¸­")
        prompt_parts.append("")
        prompt_parts.append("ç¤ºä¾‹3ï¼šæ•°å€¼èŒƒå›´æ£€æŸ¥")
        prompt_parts.append("è§„åˆ™ï¼šIF NOT (å¤§äºç­‰äº0MPaå¹¶ä¸”å°äºç­‰äº100MPa) THEN æ ‡è®°é”™è¯¯('ä¸æ»¡è¶³èŒƒå›´')")
        prompt_parts.append("æ•°æ®ï¼šæ“ä½œå‹åŠ›=150MPa")
        prompt_parts.append("è¾“å‡ºï¼šè®°å½•1|æ“ä½œå‹åŠ›|ä¸åˆæ ¼|150MPaè¶…å‡º0-100MPaèŒƒå›´")
        prompt_parts.append("")
        prompt_parts.append("ç¤ºä¾‹4ï¼šå…¨éƒ¨é€šè¿‡")
        prompt_parts.append("è§„åˆ™ï¼šIF is_null_or_blank(æŠ¥å‘Šç¼–å·) THEN æ ‡è®°é”™è¯¯('å­—æ®µä¸èƒ½ä¸ºç©º')")
        prompt_parts.append("æ•°æ®ï¼šæŠ¥å‘Šç¼–å·='RPT-2025-001'")
        prompt_parts.append("è¾“å‡ºï¼šè®°å½•1|æŠ¥å‘Šç¼–å·|åˆæ ¼|ç¬¦åˆæ‰€æœ‰è§„åˆ™è¦æ±‚")
        prompt_parts.append("")
        
        # æ£€æŸ¥æ•°æ® - ç»“æ„åŒ–å±•ç¤º
        prompt_parts.append("=" * 60)
        prompt_parts.append("ã€å¾…æ£€æŸ¥æ•°æ®ã€‘")
        prompt_parts.append("=" * 60)
        prompt_parts.append("")
        for item in batch_data:
            record_idx = item['record_idx']
            field_name = item['field_name']
            field_value = item['field_value']
            kb_field_name = item['kb_field_name']
            quality_spec = item['quality_spec']
            category = item['category']
            
            # æ¸…æ™°çš„ç»“æ„åŒ–å±•ç¤º
            prompt_parts.append(f"ã€è®°å½•{record_idx}ã€‘")
            prompt_parts.append(f"å­—æ®µåç§°ï¼š{kb_field_name}")
            prompt_parts.append(f"å­—æ®µå€¼ï¼š{field_value}")
            prompt_parts.append(f"å­—æ®µç±»åˆ«ï¼š{category}")
            prompt_parts.append(f"è´¨æ£€è§„åˆ™ï¼š")
            # å°†å¤šè¡Œè§„åˆ™åˆ†è¡Œæ˜¾ç¤ºï¼Œæé«˜å¯è¯»æ€§
            if quality_spec:
                spec_lines = quality_spec.strip().split(';')
                for i, line in enumerate(spec_lines, 1):
                    if line.strip():
                        prompt_parts.append(f"  è§„åˆ™{i}ï¼‰{line.strip()}")
            prompt_parts.append("")
        
        # æœ€ç»ˆæŒ‡ä»¤
        prompt_parts.append("ã€æ‰§è¡Œè¦æ±‚ã€‘å¿…é¡»100%éµå®ˆ")
        prompt_parts.append("")
        prompt_parts.append("1. è§„åˆ™æ‰§è¡ŒåŸåˆ™ï¼š")
        prompt_parts.append("   âœ“ IF-THENè§„åˆ™æ˜¯å”¯ä¸€åˆ¤æ–­ä¾æ®ï¼Œä¸å¾—ä½¿ç”¨å¸¸è¯†æˆ–ç»éªŒåˆ¤æ–­")
        prompt_parts.append("   âœ“ è§„åˆ™ä¸­çš„æ¯ä¸ªé€»è¾‘æ¡ä»¶éƒ½å¿…é¡»ç²¾ç¡®è®¡ç®—ï¼Œä¸å¾—è¿‘ä¼¼æˆ–æ¨¡ç³Šåˆ¤æ–­")
        prompt_parts.append("   âœ“ ç©ºå€¼(null/None/NaN/ç©ºå­—ç¬¦ä¸²/çº¯ç©ºæ ¼)å¿…é¡»é€šè¿‡is_null_or_blank()åˆ¤æ–­")
        prompt_parts.append("   âœ“ æšä¸¾å€¼å¿…é¡»å®Œå…¨åŒ¹é…ï¼ˆåŒ…æ‹¬ä¸­æ–‡æ ‡ç‚¹ã€å¤§å°å†™ï¼‰")
        prompt_parts.append("   âœ“ æ•°å€¼èŒƒå›´å¿…é¡»åŒ…æ‹¬å•ä½åˆ¤æ–­ï¼ˆMPaâ‰ kPaâ‰ KPaï¼‰")
        prompt_parts.append("")
        prompt_parts.append("2. è¾“å‡ºæ ¼å¼åŸåˆ™ï¼š")
        prompt_parts.append("   âœ“ æ¯æ¡è®°å½•å•ç‹¬ä¸€è¡Œï¼šè®°å½•ç¼–å·|å­—æ®µå|ç»“æœ|è¯¦ç»†è¯´æ˜")
        prompt_parts.append("   âœ“ ç»“æœåªèƒ½æ˜¯'åˆæ ¼'æˆ–'ä¸åˆæ ¼'ï¼ˆæ— ç¬¬ä¸‰ç§è¡¨è¿°ï¼‰")
        prompt_parts.append("   âœ“ è¯¦ç»†è¯´æ˜å¿…é¡»æŒ‡å‡ºå…·ä½“è§¦å‘çš„è§„åˆ™æˆ–é€šè¿‡çš„åŸå› ")
        prompt_parts.append("   âœ“ ä¸å¾—è¾“å‡ºä»»ä½•é¢å¤–çš„è§£é‡Šã€æ€»ç»“ã€æ ‡é¢˜ã€åˆ†éš”çº¿")
        prompt_parts.append("")
        prompt_parts.append("3. ç‰¹æ®Šæƒ…å†µå¤„ç†ï¼š")
        prompt_parts.append("   âœ“ ä¸€ä¸ªå­—æ®µæœ‰å¤šæ¡è§„åˆ™ï¼šä»»æ„ä¸€æ¡è§¦å‘å³åˆ¤å®šä¸åˆæ ¼")
        prompt_parts.append("   âœ“ è§„åˆ™åŒ…å«å¤šä¸ªORæ¡ä»¶ï¼šåªè¦æ»¡è¶³ä¸€ä¸ªå³é€šè¿‡è¯¥è§„åˆ™")
        prompt_parts.append("   âœ“ è§„åˆ™åŒ…å«ANDæ¡ä»¶ï¼šå¿…é¡»å…¨éƒ¨æ»¡è¶³æ‰é€šè¿‡è¯¥è§„åˆ™")
        prompt_parts.append("")
        prompt_parts.append("ç°åœ¨å¼€å§‹æ‰§è¡Œè´¨æ£€ï¼Œè¾“å‡ºç»“æœï¼š")
        
        return "\n".join(prompt_parts)
    
    def _parse_batch_response(self, response_content, batch_data):
        """è§£ææ‰¹å¤„ç†çš„å“åº”ç»“æœ - æ”¹è¿›ç‰ˆæœ¬"""
        results = []
        lines = response_content.strip().split('\n')
        
        # è°ƒè¯•ä¿¡æ¯
        print(f"è§£ææ‰¹å¤„ç†å“åº”ï¼Œå…± {len(lines)} è¡Œï¼Œ{len(batch_data)} ä¸ªæ£€æŸ¥é¡¹")
        print(f"å“åº”å†…å®¹å‰200å­—ç¬¦: {response_content[:200]}...")
        
        for item in batch_data:
            record_idx = item['record_idx']
            field_name = item['field_name']
            field_value = item['field_value']
            kb_field_name = item['kb_field_name']
            quality_spec = item['quality_spec']
            category = item['category']
            
            # å°è¯•ä»å“åº”ä¸­æŸ¥æ‰¾å¯¹åº”çš„ç»“æœ
            result_found = False
            is_passed = True  # é»˜è®¤å‡è®¾åˆæ ¼
            explanation = "æœªæ‰¾åˆ°å¯¹åº”ç»“æœï¼Œé»˜è®¤æ ‡è®°ä¸ºåˆæ ¼"
            
            # æ–¹æ³•1: ç²¾ç¡®åŒ¹é…è®°å½•ç¼–å·å’Œå­—æ®µå
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                # æ£€æŸ¥æ˜¯å¦åŒ…å«è®°å½•ç¼–å·å’Œå­—æ®µåï¼ˆå¤„ç†ä¸åŒçš„æ ¼å¼ï¼‰
                if (f"è®°å½•{record_idx}" in line and (f"å­—æ®µ'{kb_field_name}'" in line or f"å­—æ®µ\"{kb_field_name}\"" in line)) or \
                   (str(record_idx) in line and kb_field_name in line):
                    print(f"æ‰¾åˆ°åŒ¹é…è¡Œ: {line}")
                    
                    # è§£æç»“æœ
                    if "|" in line:
                        parts = line.split("|")
                        if len(parts) >= 3:
                            result = parts[2].strip()
                            explanation = parts[3].strip() if len(parts) > 3 else ""
                            is_passed = "ä¸åˆæ ¼" not in result and "ä¸ç¬¦åˆ" not in result
                            result_found = True
                            print(f"è®°å½•{record_idx} è§£æç»“æœ: {result} -> {'åˆæ ¼' if is_passed else 'ä¸åˆæ ¼'}")
                            break
                    else:
                        # å¦‚æœæ²¡æœ‰åˆ†éš”ç¬¦ï¼Œå°è¯•ç›´æ¥åˆ¤æ–­
                        is_passed = "ä¸åˆæ ¼" not in line and "ä¸ç¬¦åˆ" not in line
                        explanation = line
                        result_found = True
                        print(f"è®°å½•{record_idx} ç›´æ¥åˆ¤æ–­: {'åˆæ ¼' if is_passed else 'ä¸åˆæ ¼'}")
                        break
            
            # æ–¹æ³•2: å¦‚æœç²¾ç¡®åŒ¹é…å¤±è´¥ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…
            if not result_found:
                for line in lines:
                    line = line.strip()
                    if not line:
                        continue
                        
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«è®°å½•ç¼–å·ï¼ˆæ›´å®½æ¾çš„åŒ¹é…ï¼‰
                    if f"è®°å½•{record_idx}" in line or str(record_idx) in line:
                        print(f"æ¨¡ç³ŠåŒ¹é…æ‰¾åˆ°è¡Œ: {line}")
                        
                        if "|" in line:
                            parts = line.split("|")
                            if len(parts) >= 3:
                                result = parts[2].strip()
                                explanation = parts[3].strip() if len(parts) > 3 else ""
                                is_passed = "ä¸åˆæ ¼" not in result and "ä¸ç¬¦åˆ" not in result
                                result_found = True
                                print(f"è®°å½•{record_idx} æ¨¡ç³Šè§£æç»“æœ: {result} -> {'åˆæ ¼' if is_passed else 'ä¸åˆæ ¼'}")
                                break
                        else:
                            # ç›´æ¥åˆ¤æ–­
                            is_passed = "ä¸åˆæ ¼" not in line and "ä¸ç¬¦åˆ" not in line
                            explanation = line
                            result_found = True
                            print(f"è®°å½•{record_idx} æ¨¡ç³Šç›´æ¥åˆ¤æ–­: {'åˆæ ¼' if is_passed else 'ä¸åˆæ ¼'}")
                            break
            
            # æ–¹æ³•3: å¦‚æœä»ç„¶æ‰¾ä¸åˆ°ï¼Œè¿›è¡Œæ™ºèƒ½æ¨æ–­
            if not result_found:
                print(f"è®°å½•{record_idx} æœªæ‰¾åˆ°å¯¹åº”ç»“æœï¼Œè¿›è¡Œæ™ºèƒ½æ¨æ–­...")
                
                # æ£€æŸ¥æ•´ä¸ªå“åº”ä¸­æ˜¯å¦æœ‰å…³äºè¿™ä¸ªè®°å½•çš„ä¿¡æ¯
                record_mentioned = False
                for line in lines:
                    if f"è®°å½•{record_idx}" in line or str(record_idx) in line:
                        record_mentioned = True
                        break
                
                if record_mentioned:
                    # å¦‚æœè®°å½•è¢«æåˆ°ä½†ç»“æœä¸æ˜ç¡®ï¼Œæ ‡è®°ä¸ºéœ€è¦äººå·¥æ£€æŸ¥
                    is_passed = False
                    explanation = "è®°å½•è¢«æåˆ°ä½†ç»“æœä¸æ˜ç¡®ï¼Œéœ€è¦äººå·¥æ£€æŸ¥"
                else:
                    # å¦‚æœè®°å½•å®Œå…¨æ²¡æœ‰è¢«æåˆ°ï¼Œå¯èƒ½æ˜¯å¤§æ¨¡å‹é—æ¼äº†ï¼Œæ ‡è®°ä¸ºåˆæ ¼
                    is_passed = True
                    explanation = "è®°å½•æœªè¢«å¤§æ¨¡å‹å¤„ç†ï¼Œé»˜è®¤æ ‡è®°ä¸ºåˆæ ¼"
            
            results.append({
                'è®°å½•ç¼–å·': record_idx,
                'åŸå­—æ®µ': field_name,
                'æ˜ å°„å­—æ®µ': kb_field_name,
                'å˜é‡': kb_field_name,
                'å€¼': str(field_value),
                'ç±»åˆ«': category,
                'ç»“æœ': 'åˆæ ¼' if is_passed else 'ä¸åˆæ ¼',
                'è¯´æ˜': explanation,
                'è§„èŒƒ': quality_spec
            })
        
        # ç»Ÿè®¡è§£æç»“æœ
        passed_count = sum(1 for r in results if r['ç»“æœ'] == 'åˆæ ¼')
        failed_count = sum(1 for r in results if r['ç»“æœ'] == 'ä¸åˆæ ¼')
        print(f"æ‰¹å¤„ç†è§£æå®Œæˆ: åˆæ ¼ {passed_count} ä¸ªï¼Œä¸åˆæ ¼ {failed_count} ä¸ª")
        
        return results
    
    def _call_llm_with_retry(self, prompt, batch_idx, total_batches):
        """å¸¦é‡è¯•æœºåˆ¶çš„LLMè°ƒç”¨"""
        for attempt in range(self._max_retries):
            try:
                print(f"[æ‰¹æ¬¡ {batch_idx}/{total_batches}] è°ƒç”¨å¤§æ¨¡å‹APIï¼Œæ£€æŸ¥å­—æ®µå€¼... (å°è¯• {attempt + 1}/{self._max_retries})")
                
                # ä¼˜å…ˆä½¿ç”¨ç®€åŒ–ç‰ˆæ–¹æ³•
                response_content = self.llm_client.generate_sync_simple(prompt)
                
                if response_content and response_content.strip():
                    return response_content
                
                # å¦‚æœç®€åŒ–ç‰ˆè¿”å›ç©ºç»“æœï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•
                print(f"[æ‰¹æ¬¡ {batch_idx}/{total_batches}] ç®€åŒ–ç‰ˆè¿”å›ç©ºç»“æœï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•...")
                response_content = self.llm_client.generate_sync(prompt)
                
                if response_content and response_content.strip():
                    return response_content
                
                # å¦‚æœä¸¤ç§æ–¹æ³•éƒ½è¿”å›ç©ºç»“æœï¼Œç­‰å¾…åé‡è¯•
                if attempt < self._max_retries - 1:
                    print(f"[æ‰¹æ¬¡ {batch_idx}/{total_batches}] ä¸¤ç§æ–¹æ³•éƒ½è¿”å›ç©ºç»“æœï¼Œç­‰å¾… {self._retry_delay} ç§’åé‡è¯•...")
                    time.sleep(self._retry_delay)
                    continue
                    
            except Exception as e:
                error_msg = str(e)
                print(f"[æ‰¹æ¬¡ {batch_idx}/{total_batches}] å°è¯• {attempt + 1} å¤±è´¥: {error_msg}")
                
                # å¦‚æœæ˜¯äº‹ä»¶å¾ªç¯ç›¸å…³é”™è¯¯ï¼Œå¢åŠ å»¶è¿Ÿ
                if "Event loop is closed" in error_msg or "asyncio" in error_msg.lower():
                    delay = self._retry_delay * (attempt + 1)  # é€’å¢å»¶è¿Ÿ
                    print(f"[æ‰¹æ¬¡ {batch_idx}/{total_batches}] æ£€æµ‹åˆ°äº‹ä»¶å¾ªç¯é”™è¯¯ï¼Œç­‰å¾… {delay} ç§’åé‡è¯•...")
                    time.sleep(delay)
                
                # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æœ
                if attempt == self._max_retries - 1:
                    print(f"[æ‰¹æ¬¡ {batch_idx}/{total_batches}] æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å¤„ç†")
                    return "æ‰€æœ‰è®°å½•å‡åˆæ ¼"
                
                # ç­‰å¾…åé‡è¯•
                time.sleep(self._retry_delay)
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æœ
        return "æ‰€æœ‰è®°å½•å‡åˆæ ¼"

    def _cleanup_event_loop(self):
        """æ¸…ç†äº‹ä»¶å¾ªç¯ï¼Œé˜²æ­¢Event loop is closedé”™è¯¯"""
        try:
            import asyncio
            # æ¸…ç†å¯èƒ½å­˜åœ¨çš„æ—§å¾ªç¯
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    loop.stop()
                if not loop.is_closed():
                    loop.close()
            except:
                pass
        except:
            pass

    def run_quality_check(self, db_config, table_name, fields=None, created_by="", knowledge_base_id=None, field_mappings=None, limit=None):
        """è¿è¡Œæ–‡æœ¬è´¨æ£€ï¼ˆæ‰¹å¤„ç†ç‰ˆæœ¬ï¼‰
        
        Args:
            db_config: æ•°æ®åº“é…ç½®
            table_name: è¡¨å
            fields: å­—æ®µåˆ—è¡¨
            created_by: åˆ›å»ºè€…
            knowledge_base_id: çŸ¥è¯†åº“IDï¼ˆä¿ç•™ä½†ä¸ä½¿ç”¨ï¼‰
            field_mappings: å­—æ®µæ˜ å°„å­—å…¸
            limit: æ•°æ®é‡é™åˆ¶ï¼ŒNoneè¡¨ç¤ºä¸é™åˆ¶
        """
        start_time = time.time()
        debug_logs = []  # æ”¶é›†è°ƒè¯•ä¿¡æ¯
        
        try:
            debug_logs.append("å¼€å§‹æ‰§è¡Œæ–‡æœ¬æ•°æ®è´¨æ£€ï¼ˆæ‰¹å¤„ç†æ¨¡å¼ï¼‰...")
            
            # 1. åŠ è½½çŸ¥è¯†åº“æ•°æ® - ä»Excelæ–‡ä»¶è¯»å–
            try:
                debug_logs.append("ä»Excelæ–‡ä»¶åŠ è½½çŸ¥è¯†åº“...")
                knowledge_base = self.load_embedded_knowledge_base()
                debug_logs.append(f"æˆåŠŸä»Excelæ–‡ä»¶åŠ è½½çŸ¥è¯†åº“ï¼ŒåŒ…å« {len(knowledge_base)} æ¡è®°å½•")
                
                # æ˜¾ç¤ºå‰å‡ æ¡çŸ¥è¯†åº“è®°å½•ç”¨äºè°ƒè¯•
                for i, item in enumerate(knowledge_base[:3]):
                    debug_logs.append(f"çŸ¥è¯†åº“è®°å½• {i+1}: Variable='{item['Variable']}', Category='{item['Category']}'")
                    
            except Exception as kb_error:
                debug_logs.append(f"åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {str(kb_error)}")
                return {
                    'success': False,
                    'error': f'åŠ è½½çŸ¥è¯†åº“å¤±è´¥: {str(kb_error)}',
                    'debug_logs': debug_logs
                }
            
            # 2. ä»æ•°æ®åº“è¯»å–æ•°æ®è¿›è¡Œè´¨æ£€
            limit_info = f"ï¼ˆé™åˆ¶ {limit} æ¡ï¼‰" if limit else "ï¼ˆå…¨é‡æ•°æ®ï¼‰"
            debug_logs.append(f"ä»æ•°æ®åº“è¯»å–æ•°æ®{limit_info}...")
            try:
                data_records = DatabaseService.preview_data_with_filter(
                    db_config=db_config, 
                    table_name=table_name, 
                    fields=fields,
                    limit=limit,  # ä½¿ç”¨ä¼ å…¥çš„limitå‚æ•°
                    company_field=None,
                    company_value=None
                )
                
                if not data_records:
                    debug_logs.append("æ•°æ®åº“æŸ¥è¯¢ç»“æœä¸ºç©º")
                    return {
                        'success': False,
                        'error': 'æ²¡æœ‰æ‰¾åˆ°æ•°æ®',
                        'debug_logs': debug_logs
                    }
                
                debug_logs.append(f"è·å–åˆ° {len(data_records)} æ¡è®°å½•")
                
                # æ˜¾ç¤ºç¬¬ä¸€æ¡è®°å½•çš„å­—æ®µåç”¨äºè°ƒè¯•
                if data_records:
                    first_record = data_records[0]
                    field_names = list(first_record.keys())
                    debug_logs.append(f"æ•°æ®å­—æ®µ: {field_names}")
                    
            except Exception as db_error:
                debug_logs.append(f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {str(db_error)}")
                return {
                    'success': False,
                    'error': f'æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {str(db_error)}',
                    'debug_logs': debug_logs
                }
            
            # 3. åˆ›å»ºçŸ¥è¯†åº“å­—æ®µæ˜ å°„
            kb_map = {item['Variable']: item for item in knowledge_base if item['Variable']}
            debug_logs.append(f"çŸ¥è¯†åº“å­—æ®µæ˜ å°„: {list(kb_map.keys())}")
            
            # 4. å¤„ç†å­—æ®µæ˜ å°„ï¼ˆè‹±æ–‡å­—æ®µå -> ä¸­æ–‡æè¿°ï¼‰
            if field_mappings:
                debug_logs.append(f"ä½¿ç”¨å­—æ®µæ˜ å°„: {field_mappings}")
            else:
                debug_logs.append("æœªæä¾›å­—æ®µæ˜ å°„ï¼Œå°†å°è¯•ç›´æ¥åŒ¹é…")
            
            # æ£€æŸ¥å­—æ®µåŒ¹é…æƒ…å†µ
            if data_records:
                data_fields = set(data_records[0].keys())
                kb_fields = set(kb_map.keys())
                
                # å¦‚æœæœ‰å­—æ®µæ˜ å°„ï¼Œæ£€æŸ¥æ˜ å°„åçš„åŒ¹é…æƒ…å†µ
                if field_mappings:
                    mapped_matches = []
                    for eng_field in data_fields:
                        if eng_field in field_mappings:
                            chinese_desc = field_mappings[eng_field]
                            if chinese_desc in kb_map:
                                mapped_matches.append(f"{eng_field} -> {chinese_desc}")
                    debug_logs.append(f"å­—æ®µæ˜ å°„åŒ¹é…: {mapped_matches}")
                    if not mapped_matches:
                        debug_logs.append("å­—æ®µæ˜ å°„åä»æ— æ³•åŒ¹é…çŸ¥è¯†åº“è§„åˆ™")
                else:
                    # ç›´æ¥åŒ¹é…
                    matched_fields = data_fields.intersection(kb_fields)
                    debug_logs.append(f"ç›´æ¥åŒ¹é…çš„å­—æ®µ: {list(matched_fields)}")
                    if not matched_fields:
                        debug_logs.append("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å­—æ®µï¼æ•°æ®åº“å­—æ®µä¸çŸ¥è¯†åº“å˜é‡ä¸åŒ¹é…")
            
            # 5. é¢„å¤„ç†å­—æ®µæ˜ å°„ä¿¡æ¯
            field_mapping_info = {}
            if field_mappings:
                for eng_field, chn_desc in field_mappings.items():
                    if eng_field in data_records[0].keys() and chn_desc in kb_map:
                        field_mapping_info[eng_field] = {
                            'chinese_name': chn_desc,
                            'kb_entry': kb_map[chn_desc]
                        }
                        debug_logs.append(f"å­—æ®µæ˜ å°„é…ç½®: {eng_field} -> {chn_desc}")
            
            # 6. æ”¶é›†æ‰€æœ‰éœ€è¦è´¨æ£€çš„æ•°æ®é¡¹
            all_check_items = []
            for record_idx, record in enumerate(data_records, 1):
                for field_name, field_value in record.items():
                    # ç¡®å®šè¦ä½¿ç”¨çš„çŸ¥è¯†åº“å­—æ®µå
                    kb_field_name = field_name  # é»˜è®¤ä½¿ç”¨åŸå­—æ®µå
                    kb_entry = None
                    
                    # å¦‚æœæœ‰å­—æ®µæ˜ å°„ï¼Œä½¿ç”¨é¢„å¤„ç†çš„æ˜ å°„ä¿¡æ¯
                    if field_name in field_mapping_info:
                        kb_field_name = field_mapping_info[field_name]['chinese_name']
                        kb_entry = field_mapping_info[field_name]['kb_entry']
                    
                    # æ£€æŸ¥å­—æ®µæ˜¯å¦åœ¨çŸ¥è¯†åº“ä¸­ï¼ˆä¼˜å…ˆä½¿ç”¨é¢„å¤„ç†çš„æ˜ å°„ä¿¡æ¯ï¼‰
                    if kb_entry or kb_field_name in kb_map:
                        if not kb_entry:
                            kb_entry = kb_map[kb_field_name]
                            
                        quality_spec = kb_entry['è´¨é‡è§„èŒƒæè¿°']
                        category = kb_entry['Category']
                        
                        all_check_items.append({
                            'record_idx': record_idx,
                            'field_name': field_name,
                            'field_value': field_value,
                            'kb_field_name': kb_field_name,
                            'quality_spec': quality_spec,
                            'category': category
                        })
            
            debug_logs.append(f"ğŸ“‹ å°†å¤„ç† {len(all_check_items)} ä¸ªå­—æ®µå€¼ï¼Œä½¿ç”¨æ‰¹å¤„ç†æ¨¡å¼ï¼ˆæ¯{self.batch_size}æ¡ï¼‰")
            debug_logs.append("--- å¼€å§‹æ‰§è¡Œæ‰¹å¤„ç†è´¨æ£€ ---")
            
            # 7. é¢„å¤„ç†äº•åå­—æ®µï¼ˆä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼Œä¸è°ƒç”¨å¤§æ¨¡å‹ï¼‰
            debug_logs.append("ğŸ” å¼€å§‹é¢„å¤„ç†äº•åå­—æ®µ...")
            well_name_results, remaining_items = self._preprocess_well_name_fields(all_check_items)
            quality_results = well_name_results.copy()  # å…ˆä¿å­˜äº•åéªŒè¯ç»“æœ
            
            debug_logs.append(f"âœ… äº•åé¢„å¤„ç†å®Œæˆ: æ­£åˆ™éªŒè¯ {len(well_name_results)} ä¸ªï¼Œå¾…å¤§æ¨¡å‹æ£€æŸ¥ {len(remaining_items)} ä¸ª")
            
            # 8. æ‰¹å¤„ç†è´¨æ£€ï¼ˆåªå¤„ç†éäº•åå­—æ®µï¼‰
            if remaining_items:
                total_batches = (len(remaining_items) + self.batch_size - 1) // self.batch_size
                
                for batch_idx in range(total_batches):
                    start_idx = batch_idx * self.batch_size
                    end_idx = min(start_idx + self.batch_size, len(remaining_items))
                    batch_items = remaining_items[start_idx:end_idx]
                    
                    debug_logs.append(f"å¤„ç†æ‰¹æ¬¡ {batch_idx + 1}/{total_batches}ï¼ŒåŒ…å« {len(batch_items)} ä¸ªæ£€æŸ¥é¡¹")
                    
                    # åˆ›å»ºæ‰¹å¤„ç†çš„prompt
                    batch_prompt = self._create_batch_prompt(batch_items, field_mapping_info, kb_map)
                    
                    # è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œæ‰¹å¤„ç†è´¨æ£€ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
                    response_content = self._call_llm_with_retry(batch_prompt, batch_idx + 1, total_batches)
                    
                    # è§£ææ‰¹å¤„ç†ç»“æœ
                    batch_results = self._parse_batch_response(response_content, batch_items)
                    quality_results.extend(batch_results)
                    
                    print(f"[æ‰¹æ¬¡ {batch_idx + 1}/{total_batches}] å®Œæˆï¼Œè§£æåˆ° {len(batch_results)} ä¸ªç»“æœ")
                    
                    # æ‰¹æ¬¡é—´å»¶è¿Ÿï¼Œé¿å…APIè°ƒç”¨è¿‡äºé¢‘ç¹
                    if batch_idx < total_batches - 1:
                        time.sleep(0.5)
            else:
                debug_logs.append("âœ… æ‰€æœ‰å­—æ®µéƒ½æ˜¯äº•åå­—æ®µï¼Œæ— éœ€è°ƒç”¨å¤§æ¨¡å‹")
                total_batches = 0
            
            # 9. è¾“å‡ºå¤„ç†å®Œæˆä¿¡æ¯
            debug_logs.append(f"âœ… æ‰¹å¤„ç†è´¨æ£€å®Œæˆï¼å…±å¤„ç† {len(quality_results)} ä¸ªå­—æ®µå€¼")
            debug_logs.append("--- è´¨æ£€ç»“æœç»Ÿè®¡ ---")
            
            # 10. è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            total_count = len(quality_results)
            passed_count = sum(1 for r in quality_results if r['ç»“æœ'] == 'åˆæ ¼')
            failed_count = sum(1 for r in quality_results if r['ç»“æœ'] == 'ä¸åˆæ ¼')
            error_count = sum(1 for r in quality_results if r['ç»“æœ'] == 'æ£€æŸ¥å¤±è´¥')
            pass_rate = (passed_count / total_count * 100) if total_count > 0 else 0
            execution_time = time.time() - start_time
            
            # ç»Ÿè®¡äº•åéªŒè¯ç»“æœ
            well_name_count = len(well_name_results)
            well_name_passed = sum(1 for r in well_name_results if r['ç»“æœ'] == 'åˆæ ¼')
            well_name_failed = sum(1 for r in well_name_results if r['ç»“æœ'] == 'ä¸åˆæ ¼')
            
            print(f"\n=== æ‰¹å¤„ç†è´¨æ£€å®Œæˆ ===")
            print(f"æ€»æ£€æŸ¥é¡¹: {total_count}")
            print(f"äº•åæ­£åˆ™éªŒè¯: {well_name_count} ä¸ª (åˆæ ¼: {well_name_passed}, ä¸åˆæ ¼: {well_name_failed})")
            print(f"å¤§æ¨¡å‹æ£€æŸ¥: {len(remaining_items)} ä¸ª")
            print(f"åˆæ ¼: {passed_count}")
            print(f"ä¸åˆæ ¼: {failed_count}")
            print(f"æ£€æŸ¥å¤±è´¥: {error_count}")
            print(f"åˆæ ¼ç‡: {pass_rate:.2f}%")
            print(f"æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
            print(f"æ‰¹å¤„ç†æ•°: {total_batches}")
            
            # 11. ä¿å­˜ç»“æœåˆ°æ•°æ®åº“
            result_id = self._save_quality_results(
                quality_results, 
                db_config, 
                table_name, 
                created_by,
                passed_count,
                failed_count,
                pass_rate,
                execution_time
            )
            
            # 12. æœ€ç»ˆæ¸…ç†äº‹ä»¶å¾ªç¯
            print("è´¨æ£€å®Œæˆï¼Œæ‰§è¡Œæœ€ç»ˆæ¸…ç†...")
            self._cleanup_event_loop()
            
            return {
                'success': True,
                'data': {
                    'id': result_id,
                    'results': quality_results,
                    'total_records': total_count,
                    'passed_records': passed_count,
                    'failed_records': failed_count,
                    'pass_rate': round(pass_rate, 2),
                    'execution_time': round(execution_time, 2),
                    'total_batches': total_batches,
                    'batch_size': self.batch_size,
                    'reports': self._generate_reports(quality_results),
                    'debug_logs': debug_logs  # æ·»åŠ è°ƒè¯•æ—¥å¿—
                }
            }
            
        except Exception as e:
            debug_logs.append(f"è´¨æ£€æµç¨‹å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'debug_logs': debug_logs
            }
    
    def _generate_reports(self, quality_results):
        """ç”ŸæˆæŠ¥å‘Šæ ¼å¼"""
        reports = {}
        
        # æŒ‰å­—æ®µåˆ†ç»„ç»Ÿè®¡
        for result in quality_results:
            field_name = result['å˜é‡']
            if field_name not in reports:
                reports[field_name] = {
                    'rule_name': f"æ–‡æœ¬è´¨æ£€-{field_name}",
                    'rule_type': 'text_quality',
                    'field_name': field_name,
                    'passed_count': 0,
                    'failed_count': 0,
                    'error_details': []
                }
            
            if result['ç»“æœ'] == 'åˆæ ¼':
                reports[field_name]['passed_count'] += 1
            else:
                reports[field_name]['failed_count'] += 1
                reports[field_name]['error_details'].append({
                    'row': result['è®°å½•ç¼–å·'],
                    'value': result['å€¼'],
                    'message': result['è¯´æ˜']
                })
        
        return list(reports.values())
    
    def _save_quality_results(self, results, db_config, table_name, created_by, 
                             passed_count, failed_count, pass_rate, execution_time):
        """ä¿å­˜è´¨æ£€ç»“æœåˆ°æ•°æ®åº“"""
        try:
            # ä¿å­˜ä¸»ç»“æœ
            result = QualityResult(
                rule_library_id=None,  # æ–‡æœ¬è´¨æ£€ä¸ä½¿ç”¨è§„åˆ™åº“
                data_source=db_config.get('name', 'unknown'),
                table_name=table_name,
                total_records=len(results),
                passed_records=passed_count,
                failed_records=failed_count,
                pass_rate=pass_rate,
                execution_time=execution_time,
                created_by=created_by,
                check_type='text_llm'  # æ ‡è®°ä¸ºæ–‡æœ¬LLMæ£€æŸ¥
            )
            
            db.session.add(result)
            db.session.flush()
            
            # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
            for item in results:
                report = QualityReport(
                    result_id=result.id,
                    rule_name=f"æ–‡æœ¬è´¨æ£€-{item['å˜é‡']}",
                    rule_type='text_quality_check',
                    field_name=item['å˜é‡'],
                    passed_count=1 if item['ç»“æœ'] == 'åˆæ ¼' else 0,
                    failed_count=1 if item['ç»“æœ'] == 'ä¸åˆæ ¼' else 0
                )
                
                if item['ç»“æœ'] != 'åˆæ ¼':
                    error_details = [{
                        'record': item['è®°å½•ç¼–å·'],
                        'value': item['å€¼'],
                        'message': item['è¯´æ˜'],
                        'standard': item['è§„èŒƒ']
                    }]
                    report.set_error_details(error_details)
                
                db.session.add(report)
            
            db.session.commit()
            print(f"è´¨æ£€ç»“æœå·²ä¿å­˜åˆ°æ•°æ®åº“ï¼Œç»“æœID: {result.id}")
            return result.id
            
        except Exception as e:
            db.session.rollback()
            print(f"ä¿å­˜è´¨æ£€ç»“æœå¤±è´¥: {str(e)}")
            return None

    def optimize_knowledge_base(self):
        """ä¼˜åŒ–çŸ¥è¯†åº“ç»“æ„ï¼Œæé«˜å¤§æ¨¡å‹è¯†åˆ«æ•ˆæœ"""
        try:
            # è·å–çŸ¥è¯†åº“æ–‡ä»¶è·¯å¾„
            base_dir = os.path.dirname(os.path.dirname(__file__))
            base_dir = os.path.dirname(base_dir)
            kb_path = os.path.join(base_dir, 'æ–‡æœ¬å‹çŸ¥è¯†åº“.xlsx')
            
            if not os.path.exists(kb_path):
                raise FileNotFoundError(f"çŸ¥è¯†åº“æ–‡ä»¶æœªæ‰¾åˆ°: {kb_path}")
            
            # è¯»å–Excelæ–‡ä»¶
            df = pd.read_excel(kb_path)
            
            # ä¼˜åŒ–å»ºè®®
            optimization_suggestions = []
            
            # 1. æ£€æŸ¥å­—æ®µå®Œæ•´æ€§
            required_columns = ['Variable', 'Category', 'è´¨é‡è§„èŒƒæè¿°']
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                optimization_suggestions.append(f"ç¼ºå°‘å¿…éœ€åˆ—: {missing_columns}")
            
            # 2. æ£€æŸ¥æ•°æ®è´¨é‡
            if 'Variable' in df.columns:
                # æ£€æŸ¥å˜é‡åæ˜¯å¦è§„èŒƒ
                invalid_variables = []
                for idx, var in enumerate(df['Variable']):
                    if pd.isna(var) or str(var).strip() == '':
                        invalid_variables.append(f"ç¬¬{idx+1}è¡Œ: å˜é‡åä¸ºç©º")
                    elif len(str(var)) > 50:
                        invalid_variables.append(f"ç¬¬{idx+1}è¡Œ: å˜é‡åè¿‡é•¿({len(str(var))}å­—ç¬¦)")
                
                if invalid_variables:
                    optimization_suggestions.extend(invalid_variables)
            
            # 3. æ£€æŸ¥ç±»åˆ«æ ‡å‡†åŒ–
            if 'Category' in df.columns:
                valid_categories = ['æ•°å€¼å‹', 'æ–‡æœ¬å‹', 'æ—¥æœŸå‹', 'æšä¸¾å‹', 'å¸ƒå°”å‹']
                invalid_categories = []
                for idx, cat in enumerate(df['Category']):
                    if pd.isna(cat) or str(cat).strip() == '':
                        invalid_categories.append(f"ç¬¬{idx+1}è¡Œ: ç±»åˆ«ä¸ºç©º")
                    elif str(cat) not in valid_categories:
                        invalid_categories.append(f"ç¬¬{idx+1}è¡Œ: ç±»åˆ«'{cat}'ä¸åœ¨æ ‡å‡†ç±»åˆ«ä¸­")
                
                if invalid_categories:
                    optimization_suggestions.extend(invalid_categories)
            
            # 4. æ£€æŸ¥è´¨é‡è§„èŒƒæè¿°
            if 'è´¨é‡è§„èŒƒæè¿°' in df.columns:
                poor_descriptions = []
                for idx, desc in enumerate(df['è´¨é‡è§„èŒƒæè¿°']):
                    if pd.isna(desc) or str(desc).strip() == '':
                        poor_descriptions.append(f"ç¬¬{idx+1}è¡Œ: è´¨é‡è§„èŒƒæè¿°ä¸ºç©º")
                    elif len(str(desc)) < 10:
                        poor_descriptions.append(f"ç¬¬{idx+1}è¡Œ: è´¨é‡è§„èŒƒæè¿°è¿‡çŸ­({len(str(desc))}å­—ç¬¦)")
                    elif len(str(desc)) > 500:
                        poor_descriptions.append(f"ç¬¬{idx+1}è¡Œ: è´¨é‡è§„èŒƒæè¿°è¿‡é•¿({len(str(desc))}å­—ç¬¦)")
                
                if poor_descriptions:
                    optimization_suggestions.extend(poor_descriptions)
            
            # 5. ç”Ÿæˆä¼˜åŒ–åçš„çŸ¥è¯†åº“
            if optimization_suggestions:
                print("å‘ç°çŸ¥è¯†åº“é—®é¢˜ï¼Œå»ºè®®ä¼˜åŒ–:")
                for suggestion in optimization_suggestions:
                    print(f"  - {suggestion}")
                
                # åˆ›å»ºä¼˜åŒ–åçš„çŸ¥è¯†åº“
                optimized_df = self._create_optimized_knowledge_base(df)
                
                # ä¿å­˜ä¼˜åŒ–åçš„çŸ¥è¯†åº“
                optimized_path = os.path.join(base_dir, 'æ–‡æœ¬å‹çŸ¥è¯†åº“_ä¼˜åŒ–ç‰ˆ.xlsx')
                optimized_df.to_excel(optimized_path, index=False)
                print(f"ä¼˜åŒ–åçš„çŸ¥è¯†åº“å·²ä¿å­˜åˆ°: {optimized_path}")
                
                return {
                    'success': True,
                    'message': 'çŸ¥è¯†åº“ä¼˜åŒ–å®Œæˆ',
                    'issues_found': len(optimization_suggestions),
                    'suggestions': optimization_suggestions,
                    'optimized_file': 'æ–‡æœ¬å‹çŸ¥è¯†åº“_ä¼˜åŒ–ç‰ˆ.xlsx'
                }
            else:
                return {
                    'success': True,
                    'message': 'çŸ¥è¯†åº“ç»“æ„è‰¯å¥½ï¼Œæ— éœ€ä¼˜åŒ–',
                    'issues_found': 0,
                    'suggestions': []
                }
                
        except Exception as e:
            print(f"çŸ¥è¯†åº“ä¼˜åŒ–å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e)
            }
    
    def _create_optimized_knowledge_base(self, original_df):
        """åˆ›å»ºä¼˜åŒ–åçš„çŸ¥è¯†åº“"""
        optimized_data = []
        
        for idx, row in original_df.iterrows():
            # æ ‡å‡†åŒ–å˜é‡å
            variable = str(row.get('Variable', '')).strip()
            if not variable:
                variable = f"æœªå‘½åå˜é‡_{idx+1}"
            
            # æ ‡å‡†åŒ–ç±»åˆ«
            category = str(row.get('Category', '')).strip()
            if not category or category not in ['æ•°å€¼å‹', 'æ–‡æœ¬å‹', 'æ—¥æœŸå‹', 'æšä¸¾å‹', 'å¸ƒå°”å‹']:
                category = 'æ–‡æœ¬å‹'  # é»˜è®¤ç±»åˆ«
            
            # ä¼˜åŒ–è´¨é‡è§„èŒƒæè¿°
            description = str(row.get('è´¨é‡è§„èŒƒæè¿°', '')).strip()
            if not description:
                description = f"{category}å­—æ®µï¼Œéœ€è¦ç¬¦åˆåŸºæœ¬æ ¼å¼è¦æ±‚"
            elif len(description) < 10:
                description = f"{description}ï¼Œéœ€è¦ç¬¦åˆ{category}å­—æ®µçš„åŸºæœ¬è§„èŒƒ"
            elif len(description) > 500:
                description = description[:497] + "..."
            
            # æ·»åŠ æ–°çš„ä¼˜åŒ–å­—æ®µ
            optimized_row = {
                'Variable': variable,
                'Category': category,
                'è´¨é‡è§„èŒƒæè¿°': description,
                'æ•°æ®ç±»å‹': self._infer_data_type(category),
                'éªŒè¯è§„åˆ™': self._generate_validation_rule(category, description),
                'ç¤ºä¾‹å€¼': self._generate_example_value(category),
                'é”™è¯¯æç¤º': self._generate_error_message(category, description)
            }
            
            optimized_data.append(optimized_row)
        
        return pd.DataFrame(optimized_data)
    
    def _infer_data_type(self, category):
        """æ ¹æ®ç±»åˆ«æ¨æ–­æ•°æ®ç±»å‹"""
        type_mapping = {
            'æ•°å€¼å‹': 'float/int',
            'æ–‡æœ¬å‹': 'string',
            'æ—¥æœŸå‹': 'datetime',
            'æšä¸¾å‹': 'string',
            'å¸ƒå°”å‹': 'boolean'
        }
        return type_mapping.get(category, 'string')
    
    def _generate_validation_rule(self, category, description):
        """ç”ŸæˆéªŒè¯è§„åˆ™"""
        if category == 'æ•°å€¼å‹':
            return "å¿…é¡»æ˜¯æœ‰æ•ˆæ•°å€¼ï¼Œä¸èƒ½ä¸ºç©º"
        elif category == 'æ—¥æœŸå‹':
            return "å¿…é¡»æ˜¯æœ‰æ•ˆæ—¥æœŸæ ¼å¼(YYYY-MM-DDæˆ–YYYY/MM/DD)"
        elif category == 'æ–‡æœ¬å‹':
            return "ä¸èƒ½ä¸ºç©ºï¼Œé•¿åº¦ä¸è¶…è¿‡1000å­—ç¬¦"
        elif category == 'æšä¸¾å‹':
            return "å¿…é¡»åœ¨å…è®¸å€¼èŒƒå›´å†…"
        elif category == 'å¸ƒå°”å‹':
            return "å¿…é¡»æ˜¯true/falseæˆ–0/1"
        else:
            return "ç¬¦åˆåŸºæœ¬æ ¼å¼è¦æ±‚"
    
    def _generate_example_value(self, category):
        """ç”Ÿæˆç¤ºä¾‹å€¼"""
        example_mapping = {
            'æ•°å€¼å‹': '123.45',
            'æ–‡æœ¬å‹': 'ç¤ºä¾‹æ–‡æœ¬',
            'æ—¥æœŸå‹': '2024-01-01',
            'æšä¸¾å‹': 'é€‰é¡¹A',
            'å¸ƒå°”å‹': 'true'
        }
        return example_mapping.get(category, 'ç¤ºä¾‹å€¼')
    
    def _generate_error_message(self, category, description):
        """ç”Ÿæˆé”™è¯¯æç¤ºä¿¡æ¯"""
        if category == 'æ•°å€¼å‹':
            return f"å­—æ®µå€¼å¿…é¡»æ˜¯æœ‰æ•ˆæ•°å€¼: {description}"
        elif category == 'æ—¥æœŸå‹':
            return f"å­—æ®µå€¼å¿…é¡»æ˜¯æœ‰æ•ˆæ—¥æœŸæ ¼å¼: {description}"
        elif category == 'æ–‡æœ¬å‹':
            return f"å­—æ®µå€¼ä¸ç¬¦åˆæ–‡æœ¬è§„èŒƒ: {description}"
        elif category == 'æšä¸¾å‹':
            return f"å­—æ®µå€¼ä¸åœ¨å…è®¸èŒƒå›´å†…: {description}"
        elif category == 'å¸ƒå°”å‹':
            return f"å­—æ®µå€¼å¿…é¡»æ˜¯å¸ƒå°”ç±»å‹: {description}"
        else:
            return f"å­—æ®µå€¼ä¸ç¬¦åˆè§„èŒƒ: {description}"
