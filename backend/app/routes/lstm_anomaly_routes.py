# app/routes/lstm_anomaly_routes.py
import traceback
import numpy as np
from app.services.database_service import DatabaseService
from app.services.lstm_anomaly_service import LSTMAnomalyService
from flask import Blueprint, request, jsonify
from app.models.model_registry import get_model_config_by_param  # å¯¼å…¥æˆ‘ä»¬æ–°çš„é…ç½®è·å–å‡½æ•°
from app.utils.auth_decorator import login_required

bp = Blueprint('lstm_anomaly_routes', __name__)


@bp.route('/models', methods=['POST'])
@login_required
def create_model_config():
    """åˆ›å»ºLSTMå¼‚å¸¸æ£€æµ‹æ¨¡å‹é…ç½®"""
    try:
        data = request.get_json()
        model_config = LSTMAnomalyService.create_model_config(data)
        return jsonify({
            'success': True,
            'data': model_config.to_dict()
        }), 201
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@bp.route('/models/<int:model_id>', methods=['GET'])
@login_required
def get_model_config(model_id):
    """è·å–æŒ‡å®šIDçš„æ¨¡å‹é…ç½®"""
    try:
        model_config = LSTMAnomalyService.get_model_config(model_id)
        if not model_config:
            return jsonify({
                'success': False,
                'error': 'Model config not found'
            }), 404

        return jsonify({
            'success': True,
            'data': model_config.to_dict()
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@bp.route('/models/active', methods=['GET'])
@login_required
def get_active_model_config():
    """è·å–æ¿€æ´»çš„æ¨¡å‹é…ç½®"""
    try:
        model_type = request.args.get('type')
        model_config = LSTMAnomalyService.get_active_model_config(model_type)
        if not model_config:
            return jsonify({
                'success': False,
                'error': f'No active model config found for type: {model_type}'
            }), 404

        return jsonify({
            'success': True,
            'data': model_config.to_dict()
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@bp.route('/models/<int:model_id>', methods=['PUT'])
@login_required
def update_model_config(model_id):
    """æ›´æ–°æ¨¡å‹é…ç½®"""
    try:
        model_config = LSTMAnomalyService.get_model_config(model_id)
        if not model_config:
            return jsonify({
                'success': False,
                'error': 'Model config not found'
            }), 404

        data = request.get_json()
        updated_config = LSTMAnomalyService.update_model_config(model_id, data)
        return jsonify({
            'success': True,
            'data': updated_config.to_dict()
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@bp.route('/predict', methods=['POST'])
@login_required
def predict_well():

    """å¯¹äº•çš„åºåˆ—æ•°æ®è¿›è¡Œå¼‚å¸¸é¢„æµ‹"""
    try:
        data = request.get_json()
        model_id = data.get('model_id')
        model_type = data.get('model_type')

        # è·å–æ¨¡å‹é…ç½®
        if model_id:
            model_config = LSTMAnomalyService.get_model_config(model_id)
        else:
            model_config = LSTMAnomalyService.get_active_model_config(model_type)

        if not model_config:
            return jsonify({
                'success': False,
                'error': 'No model config found'
            }), 404

        # æ ¹æ®æ¨¡å‹ç±»å‹è¿›è¡Œé¢„æµ‹
        predictions, probabilities = LSTMAnomalyService.predict_well(model_config, **data)

        return jsonify({
            'success': True,
            'data': {
                'predictions': predictions,
                'probabilities': probabilities,
                'model_id': model_config.id
            }
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@bp.route('/detect-for-ui', methods=['POST'])
@login_required
def detect_for_ui():
    try:
        data = request.get_json()

        # è¿™æ˜¯ä¿®æ”¹åçš„æ–°é€»è¾‘ï¼Œå®ƒæ£€æŸ¥çš„æ˜¯ data_source_id
        required_fields = ['data_source_id', 'table_name', 'well_id', 'parameter']
        for field in required_fields:
            if field not in data:
                return jsonify({'success': False, 'error': f'ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}'}), 400

        data_source_id = data['data_source_id']
        table_name = data['table_name']
        well_id = data['well_id']
        parameter = data['parameter']

        # å¦‚æœå‰ç«¯ä¼ äº† schemaï¼Œæˆ‘ä»¬è¦åœ¨ä¸‹é¢ç”¨åˆ°å®ƒ
        target_schema = data.get('schema')
        
       # ğŸ”’ å¼ºåˆ¶å®æ–½æ•°æ®é‡é™åˆ¶ï¼Œä¿æŠ¤ç”Ÿäº§ç¯å¢ƒ
        MAX_LIMIT = 50000
        raw_limit = data.get('limit')
        
        # [ä¿®å¤] å¤„ç† limit ä¸º None çš„æƒ…å†µ (å¯¹åº”å‰ç«¯"å…¨éƒ¨æ•°æ®")
        if raw_limit is None:
            limit = MAX_LIMIT  # å¦‚æœç”¨æˆ·é€‰äº†"å…¨éƒ¨"ï¼Œä¸ºäº†å®‰å…¨ï¼Œå¼ºåˆ¶é™åˆ¶ä¸ºæœ€å¤§å€¼
            print(f"â„¹ï¸ ç”¨æˆ·é€‰æ‹©å…¨é‡æ•°æ®ï¼Œç³»ç»Ÿå¼ºåˆ¶é™åˆ¶ä¸º {MAX_LIMIT} æ¡ä»¥ä¿æŠ¤æ€§èƒ½")
        else:
            limit = int(raw_limit)
            
        limit = min(limit, MAX_LIMIT)  # åŒé‡ä¿é™©ï¼Œç¡®ä¿ä¸è¶…è¿‡æœ€å¤§å€¼
        start_date = data.get('start_date')  # å¯é€‰çš„æ—¶é—´èŒƒå›´
        end_date = data.get('end_date')
        
        print(f"ğŸ”’ LSTMå¼‚å¸¸æ£€æµ‹æ•°æ®é‡é™åˆ¶: {limit} æ¡ï¼ˆæœ€å¤§{MAX_LIMIT}æ¡ï¼‰")
        if start_date or end_date:
            print(f"   æ—¶é—´èŒƒå›´: {start_date or 'æœ€æ—©'} ~ {end_date or 'æœ€æ–°'}")

        from app.models.data_source import DataSource
        
        # 1. ç›´æ¥æŸ¥è¯¢ DataSource å¯¹è±¡
        source = DataSource.query.get(data_source_id)
        if not source:
            return jsonify({'success': False, 'error': f'IDä¸º {data_source_id} çš„æ•°æ®æºé…ç½®æœªæ‰¾åˆ°'}), 404
        
        # 2. æ‰‹åŠ¨æ„å»º db_config å­—å…¸
        db_config = {
            'db_type': source.db_type,
            'host': source.host,
            'port': source.port,
            'database': source.database,
            # ä¼˜å…ˆä½¿ç”¨å‰ç«¯ä¼ æ¥çš„ schemaï¼Œæ²¡æœ‰æ‰ç”¨é»˜è®¤çš„
            'schema': target_schema if target_schema else getattr(source, 'schema', 'public'),
            'username': source.username,
            'password': source.password
        }

        # ä½¿ç”¨è·å–åˆ°çš„ db_config è¿›è¡Œåç»­æ“ä½œï¼ˆæ·»åŠ limitå‚æ•°ï¼‰
        full_sequence_data = DatabaseService.get_well_parameter_sequence(
            db_config, 
            table_name, 
            well_id, 
            parameter,
            limit=limit,
            start_date=start_date,
            end_date=end_date
        )

        if not full_sequence_data:
            return jsonify({'success': True, 'anomalies': [], 'message': 'æœªæŸ¥è¯¢åˆ°ç›¸å…³æ•°æ®', 'total_points': 0})

        # ... (åç»­é€»è¾‘ä¿æŒä¸å˜) ...
        pre_checked_anomalies = []
        clean_sequence_for_model = []

        for point in full_sequence_data:
            value = point.get('value')
            try:
                numeric_value = float(value) if value is not None else None
            except (ValueError, TypeError):
                numeric_value = None

            if numeric_value == 0 or numeric_value is None:
                pre_checked_anomalies.append({
                    'value': 0 if numeric_value == 0 else 'N/A',
                    'type': 'æ•°æ®ç¼ºå¤±',
                    'timestamp': point.get('date_time_index') or point.get('tag_time')
                })
            else:
                point['value'] = numeric_value
                clean_sequence_for_model.append(point)

        model_config_dict = get_model_config_by_param(parameter)
        model_anomalies = []

        if not model_config_dict:
            print(f"Warning: æœªæ‰¾åˆ°å‚æ•° '{parameter}' å¯¹åº”çš„æ¨¡å‹é…ç½®ï¼Œè·³è¿‡æ¨¡å‹æ£€æµ‹ã€‚")
        elif not clean_sequence_for_model:
            print(f"Warning: æ¸…æ´—åæ— æœ‰æ•ˆæ•°æ®å¯ä¾›æ¨¡å‹é¢„æµ‹ã€‚")
        else:
            value_sequence = [item['value'] for item in clean_sequence_for_model]
            try:
                numeric_array = np.array(value_sequence, dtype=float)
                clean_value_list = numeric_array.tolist()
                predictions, _ = LSTMAnomalyService.predict_well_from_dict(model_config_dict,
                                                                           generic_seq=clean_value_list)
                for i, pred in enumerate(predictions):
                    if pred == 1:
                        original_point = clean_sequence_for_model[i]
                        model_anomalies.append({
                            'value': original_point['value'],
                            'type': 'æ¨¡å‹æ£€æµ‹å¼‚å¸¸',
                            'timestamp': original_point.get('date_time_index') or original_point.get('tag_time')
                        })
            except ValueError as e:
                print(f"ERROR: Failed to convert sequence to numeric array before prediction. Error: {e}")
                return jsonify(
                    {'success': False, 'error': f'æ•°æ®åºåˆ—ä¸­åŒ…å«æ— æ³•è½¬æ¢ä¸ºæ•°å­—çš„å€¼ï¼Œæ— æ³•è¿›è¡Œæ¨¡å‹é¢„æµ‹ã€‚é”™è¯¯: {e}'}), 500

        all_anomalies = pre_checked_anomalies + model_anomalies
        all_anomalies.sort(key=lambda x: x['timestamp'] or '')

        return jsonify({
            'success': True,
            'anomalies': all_anomalies,
            'total_points': len(full_sequence_data)
        })

    except Exception as e:
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500