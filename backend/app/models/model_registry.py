import os

# 获取后端根目录的绝对路径
# os.path.dirname(__file__) -> 当前文件(model_registry.py)所在的目录，即 /backend
BACKEND_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
# 构建模型文件夹的绝对路径
MODELS_BASE_PATH = os.path.join(BACKEND_DIR, 'trained_models')

# 这是管理所有模型配置的核心位置。
# 键 (key): 对应前端选择的 "数据项参数" (parameter)，例如 'woba', 'rpma'
# 值 (value): 一个字典，包含该模型的所有配置信息。
# 未来需要添加新模型时，只需在这里添加新的条目即可。
MODEL_CONFIGS = {
    'woba': {
        'name': 'lstm_woba_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_woba_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model trained for WOBA parameter.'
    },
    'rpma': {
        'name': 'lstm_rpma_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_rpma_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model trained for RPMA parameter.'
    },
    'dbtm': {
        'name': 'lstm_dbtm_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dbtm_model.pth'),
        'sequence_length': 20, 'input_size': 1, 'hidden_size': 64, 'num_layers': 2, 'num_classes': 2, 'dropout': 0.0,
        'bidirectional': False, 'model_type': 'generic', 'description': 'LSTM model for DBTM.'
    },
    'dbtv': {
        'name': 'lstm_dbtv_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dbtv_model.pth'),
        'sequence_length': 20, 'input_size': 1, 'hidden_size': 64, 'num_layers': 2, 'num_classes': 2, 'dropout': 0.0,
        'bidirectional': False, 'model_type': 'generic', 'description': 'LSTM model for DBTV.'
    },
    'dmea': {
        'name': 'lstm_dmea_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dmea_model.pth'),
        'sequence_length': 20, 'input_size': 1, 'hidden_size': 64, 'num_layers': 2, 'num_classes': 2, 'dropout': 0.0,
        'bidirectional': False, 'model_type': 'generic', 'description': 'LSTM model for DMEA.'
    },
    'dsid': {
        'name': 'lstm_dsid_model',
        # 注意：您有两个dsid模型，这里我们默认使用 lstm_dsid.pth
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dsid.pth'),
        'sequence_length': 20, 'input_size': 1, 'hidden_size': 64, 'num_layers': 2, 'num_classes': 2, 'dropout': 0.0,
        'bidirectional': False, 'model_type': 'generic', 'description': 'LSTM model for DSID.'
    },
    'dver': {
        'name': 'lstm_dver_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dver_model.pth'),
        'sequence_length': 20, 'input_size': 1, 'hidden_size': 64, 'num_layers': 2, 'num_classes': 2, 'dropout': 0.0,
        'bidirectional': False, 'model_type': 'generic', 'description': 'LSTM model for DVER.'
    },
    'ropa': {
        'name': 'lstm_ropa_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_ropa_model.pth'),
        'sequence_length': 20, 'input_size': 1, 'hidden_size': 64, 'num_layers': 2, 'num_classes': 2, 'dropout': 0.0,
        'bidirectional': False, 'model_type': 'generic', 'description': 'LSTM model for ROPA.'
    },
    'sazc': {
        'name': 'lstm_sazc_model',
        # 注意: 如果您想使用效果最好的模型, 可以将文件名改为 'lstm_sazc_model_best.pth'
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_sazc_model.pth'),
        'sequence_length': 20, 'input_size': 1, 'hidden_size': 64, 'num_layers': 2, 'num_classes': 2, 'dropout': 0.0,
        'bidirectional': False, 'model_type': 'generic', 'description': 'LSTM model for SAZC.'
    },
    'sgtf': {
        'name': 'lstm_sgtf_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_sgtf_model.pth'),
        'sequence_length': 20, 'input_size': 1, 'hidden_size': 64, 'num_layers': 2, 'num_classes': 2, 'dropout': 0.0,
        'bidirectional': False, 'model_type': 'generic', 'description': 'LSTM model for SGTF.'
    },
    'sinc': {
        'name': 'lstm_sinc_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_sinc_model.pth'),
        'sequence_length': 20, 'input_size': 1, 'hidden_size': 64, 'num_layers': 2, 'num_classes': 2, 'dropout': 0.0,
        'bidirectional': False, 'model_type': 'generic', 'description': 'LSTM model for SINC.'
    },
    'smtf': {
        'name': 'lstm_smtf_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_smtf_model.pth'),
        'sequence_length': 20, 'input_size': 1, 'hidden_size': 64, 'num_layers': 2, 'num_classes': 2, 'dropout': 0.0,
        'bidirectional': False, 'model_type': 'generic', 'description': 'LSTM model for SMTF.'
    },
    'sppa': {
        'name': 'lstm_sppa_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_sppa_model.pth'),
        'sequence_length': 20, 'input_size': 1, 'hidden_size': 64, 'num_layers': 2, 'num_classes': 2, 'dropout': 0.0,
        'bidirectional': False, 'model_type': 'generic', 'description': 'LSTM model for SPPA.'
    },
    # 新增模型配置（按字母排序，已统一为小写）
    'mfd': {
        'name': 'lstm_mfd_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_mfd_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for MFD parameter.'
    },
    'mia': {
        'name': 'lstm_mia_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_mia_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for MIA parameter.'
    },
    'mfoa': {
        'name': 'lstm_mfoa_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_mfoa_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for MFOA parameter.'
    },
    'mfop': {
        'name': 'lstm_mfop_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_mfop_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for MFOP parameter.'
    },
    'mfta': {
        'name': 'lstm_mfta_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_mfta_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for MFTA parameter.'
    },
    'mg1': {
        'name': 'lstm_mg1_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_mg1_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for MG1 parameter.'
    },
    'mpo1': {
        'name': 'lstm_mpo1_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_mpo1_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for MPO1 parameter.'
    },
    'mtha': {
        'name': 'lstm_mtha_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_mtha_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for MTHA parameter.'
    },
    'mtia': {
        'name': 'lstm_mtia_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_mtia_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for MTIA parameter.'
    },
    'nbu': {
        'name': 'lstm_nbut_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_nbut_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for NBU parameter.'
    },
    'npen': {
        'name': 'lstm_npen_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_npen_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for NPEN parameter.'
    },
    'prp': {
        'name': 'lstm_prp_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_prp_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for PRP parameter.'
    },
    'prpa': {
        'name': 'lstm_prpa_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_prpa_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for PRPA parameter.'
    },
    'sew': {
        'name': 'lstm_sew_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_sew_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for SEW parameter.'
    },
    'sns': {
        'name': 'lstm_sns_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_sns_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for SNS parameter.'
    },
    'spm2': {
        'name': 'lstm_spm2_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_spm2_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for SPM2 parameter.'
    },
    'spm3': {
        'name': 'lstm_spm3_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_spm3_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for SPM3 parameter.'
    },
    'spr1': {
        'name': 'lstm_spr1_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_spr1_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for SPR1 parameter.'
    },
    'spr2': {
        'name': 'lstm_spr2_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_spr2_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for SPR2 parameter.'
    },
    'spr3': {
        'name': 'lstm_spr3_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_spr3_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for SPR3 parameter.'
    },
    'spr4': {
        'name': 'lstm_spr4_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_spr4_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for SPR4 parameter.'
    },
    'spr5': {
        'name': 'lstm_spr5_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_spr5_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for SPR5 parameter.'
    },
    'stkc': {
        'name': 'lstm_stkc_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_stkc_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for STKC parameter.'
    },
    'tv01': {
        'name': 'lstm_tv01_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_tv01_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for TV01 parameter.'
    },
    'tva': {
        'name': 'lstm_tva_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_tva_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for TVA parameter.'
    },
    'tca': {
        'name': 'lstm_tca_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_tca_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for TCA parameter.'
    },
    'tvt': {
        'name': 'lstm_tvt_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_tvt_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for TVT parameter.'
    },
    'drtm': {
        'name': 'lstm_drtm_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_drtm_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DRTM parameter.'
    },
    'drv': {
        'name': 'lstm_drv_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_drv_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DRV parameter.'
    },
    'dsid_classifier': {
        'name': 'lstm_dsid_classifier',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dsid_classifier.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM classifier model for DSID parameter.'
    },
    'dspc': {
        'name': 'lstm_dspc_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dspc_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DSPC parameter.'
    },
    'dspt': {
        'name': 'lstm_dspt_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dspt_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DSPT parameter.'
    },
    'dsta': {
        'name': 'lstm_dsta_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dsta_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DSTA parameter.'
    },
    'dstt': {
        'name': 'lstm_dstt_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dstt_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DSTT parameter.'
    },
    'dsvm': {
        'name': 'lstm_dsvm_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dsvm_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DSVM parameter.'
    },
    'dsw': {
        'name': 'lstm_dsw_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dsw_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DSW parameter.'
    },
    'dtti': {
        'name': 'lstm_dtti_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dtti_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DTTI parameter.'
    },
    'eth': {
        'name': 'lstm_eth_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_eth_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for ETH parameter.'
    },
    'etna': {
        'name': 'lstm_etna_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_etna_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for ETNA parameter.'
    },
    'gasa': {
        'name': 'lstm_gasa_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_gasa_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for GASA parameter.'
    },
    'hkla': {
        'name': 'lstm_hkla_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_hkla_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for HKLA parameter.'
    },
    'hklx': {
        'name': 'lstm_hklx_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_hklx_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for HKLX parameter.'
    },
    'ibta': {
        'name': 'lstm_ibta_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_ibta_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for IBTA parameter.'
    },
    'ibut': {
        'name': 'lstm_ibut_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_ibut_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for IBUT parameter.'
    },
    'ipen': {
        'name': 'lstm_ipen_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_ipen_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for IPEN parameter.'
    },
    'mdia': {
        'name': 'lstm_mdia_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_mdia_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for MDIA parameter.'
    },
    'mdoa': {
        'name': 'lstm_mdoa_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_mdoa_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for MDOA parameter.'
    },
    'meth': {
        'name': 'lstm_meth_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_meth_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for METH parameter.'
    },
    'act2': {
        'name': 'lstm_act2_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_act2_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for ACT2 parameter.'
    },
    'bddi': {
        'name': 'lstm_bddi_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_bddi_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for BDDI parameter.'
    },
    'bdti': {
        'name': 'lstm_bdti_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_bdti_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for BDTI parameter.'
    },
    'bpos': {
        'name': 'lstm_bpos_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_bpos_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for BPOS parameter.'
    },
    'dchm': {
        'name': 'lstm_dchm_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dchm_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DCHM parameter.'
    },
    'dchv': {
        'name': 'lstm_dchv_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dchv_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DCHV parameter.'
    },
    'ddbm': {
        'name': 'lstm_ddbm_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_ddbm_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DDBM parameter.'
    },
    'ddbv': {
        'name': 'lstm_ddbv_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_ddbv_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DDBV parameter.'
    },
    'ddtv': {
        'name': 'lstm_ddtv_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_ddtv_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DDTV parameter.'
    },
    'dfdm': {
        'name': 'lstm_dfdm_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dfdm_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DFDM parameter.'
    },
    'dfdy': {
        'name': 'lstm_dfdy_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dfdy_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DFDY parameter.'
    },
    'dg1m': {
        'name': 'lstm_dg1m_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dg1m_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DG1M parameter.'
    },
    'dg1v': {
        'name': 'lstm_dg1v_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dg1v_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DG1V parameter.'
    },
    'dlfr': {
        'name': 'lstm_dlfr_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dlfr_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DLFR parameter.'
    },
    'dmea2': {
        'name': 'lstm_dmea2_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dmea2_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DMEA2 parameter.'
    },
    'dp1m': {
        'name': 'lstm_dp1m_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dp1m_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DP1M parameter.'
    },
    'dp1v': {
        'name': 'lstm_dp1v_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dp1v_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DP1V parameter.'
    },
    'dr1m': {
        'name': 'lstm_dr1m_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dr1m_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DR1M parameter.'
    },
    'dr2m': {
        'name': 'lstm_dr2m_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dr2m_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DR2M parameter.'
    },
    'dr2v': {
        'name': 'lstm_dr2v_model',
        'model_path': os.path.join(MODELS_BASE_PATH, 'lstm_dr2v_model.pth'),
        'sequence_length': 20,
        'input_size': 1,
        'hidden_size': 64,
        'num_layers': 2,
        'num_classes': 2,
        'dropout': 0.0,
        'bidirectional': False,
        'model_type': 'generic',
        'description': 'LSTM model for DR2V parameter.'
    }
}


def get_model_config_by_param(parameter_name):
    """
    根据前端传来的参数名，从本地注册表中获取模型配置。
    """
    # 转换为小写以确保匹配
    key = parameter_name.lower()
    config = MODEL_CONFIGS.get(key)
    if config:
        # 检查模型文件是否存在，提供更明确的错误信息
        if not os.path.exists(config['model_path']):
            raise FileNotFoundError(
                f"Model file not found for parameter '{parameter_name}'. Expected at: {config['model_path']}")
    return config